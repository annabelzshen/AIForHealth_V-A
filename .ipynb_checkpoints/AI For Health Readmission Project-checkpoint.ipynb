{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e5bc68",
   "metadata": {},
   "source": [
    "Import Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8885f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "pd.set_option('display.max_columns', 999)\n",
    "import pandas.io.sql as psql\n",
    "# plot a figure directly on Notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de052ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 19)\n"
     ]
    }
   ],
   "source": [
    "admission_table = pd.read_csv(\"data/ADMISSIONS.csv\")\n",
    "subject_ids = list(admission_table['subject_id'])\n",
    "# print(admission_table)\n",
    "# print(subject_ids)\n",
    "print(admission_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3ad7652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2164-10-23 21:09:00\n",
      "1     2126-08-14 22:32:00\n",
      "2     2125-10-04 23:36:00\n",
      "3     2149-05-26 17:19:00\n",
      "4     2163-05-14 20:43:00\n",
      "             ...         \n",
      "95    2112-05-04 08:00:00\n",
      "96    2178-05-14 20:29:00\n",
      "97    2123-11-24 14:14:00\n",
      "98    2180-07-19 06:55:00\n",
      "99    2170-12-15 03:14:00\n",
      "Name: admittime, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Iterate through table\n",
    "# Regular Table: subect_id: the whole row that is their first admssion\n",
    "# During iteration, if subject_id is already in the newTableWeAreCreating, then we have seen the subject, we are doing a readmission right now\n",
    "    # But, we have to check the time frame, because if its 30 days after the dictionary value, this is a new set of admission to consider\n",
    "# first_admission_dataframe = pd.DataFrame(columns=admission_table.columns)\n",
    "first_admission_dataframe = pd.DataFrame(columns=admission_table.columns)\n",
    "\n",
    "# Iterate over rows\n",
    "for index, row in admission_table.iterrows():\n",
    "    # check if the subject_id has been admitted before\n",
    "    if row['subject_id'] not in first_admission_dataframe['subject_id'].values:\n",
    "        # Append the row to the new DataFrame\n",
    "        first_admission_dataframe = pd.concat([first_admission_dataframe, pd.DataFrame([row])], \n",
    "                                              axis=0, ignore_index=True)\n",
    "\n",
    "print(first_admission_dataframe['admittime'])\n",
    "# # Reset the index of the new DataFrame\n",
    "# first_admission_dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a547205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5adf8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are three admission back to back less than 30 days apart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc855b",
   "metadata": {},
   "source": [
    "Important features:\n",
    "\n",
    "    Admissions table\n",
    "        diagnosis\n",
    "        admission_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09778d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "def determine_readmissions(mimic_data_path, time_window=30):\n",
    "    # Load necessary tables from MIMIC-III dataset\n",
    "    admissions = pd.read_csv(mimic_data_path + \"/ADMISSIONS.csv\")\n",
    "    patients = pd.read_csv(mimic_data_path + \"/PATIENTS.csv\")\n",
    "    diagnoses_icd = pd.read_csv(mimic_data_path + \"/DIAGNOSES_ICD.csv\")\n",
    "\n",
    "    # Merge tables to get necessary features\n",
    "    merged_data = admissions.merge(patients, on='SUBJECT_ID', how='inner')\n",
    "    merged_data = merged_data.merge(diagnoses_icd, on='HADM_ID', how='inner')\n",
    "\n",
    "    # Convert admission and discharge timestamps to datetime objects\n",
    "    merged_data['ADMITTIME'] = pd.to_datetime(merged_data['ADMITTIME'])\n",
    "    merged_data['DISCHTIME'] = pd.to_datetime(merged_data['DISCHTIME'])\n",
    "\n",
    "    # Calculate readmission within time_window days\n",
    "    merged_data.sort_values(['SUBJECT_ID', 'ADMITTIME'], inplace=True)\n",
    "    merged_data['NEXT_ADMITTIME'] = merged_data.groupby('SUBJECT_ID')['ADMITTIME'].shift(-1)\n",
    "    merged_data['DAYS_TO_NEXT_READMISSION'] = (merged_data['NEXT_ADMITTIME'] - merged_data['DISCHTIME']).dt.total_seconds() / (24 * 60 * 60)\n",
    "    merged_data['READMITTED'] = merged_data['DAYS_TO_NEXT_READMISSION'].apply(lambda x: 1 if x <= time_window else 0)\n",
    "\n",
    "    # Feature selection\n",
    "    features = ['AGE', 'GENDER', 'DIAGNOSIS']\n",
    "    selected_data = merged_data[features]\n",
    "\n",
    "    # One-hot encoding for categorical variables\n",
    "    selected_data = pd.get_dummies(selected_data, columns=['GENDER', 'DIAGNOSIS'])\n",
    "\n",
    "    # Split dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(selected_data.drop('READMITTED', axis=1), selected_data['READMITTED'], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    # Extract important features\n",
    "    importance = np.abs(model.coef_[0])\n",
    "    feature_names = selected_data.drop('READMITTED', axis=1).columns\n",
    "    feature_importance = dict(zip(feature_names, importance))\n",
    "\n",
    "    return train_accuracy, test_accuracy, feature_importance\n",
    "\n",
    "# Example usage\n",
    "mimic_data_path = \"/path/to/mimic-iii/data\"\n",
    "train_acc, test_acc, important_features = determine_readmissions(mimic_data_path)\n",
    "print(\"Train accuracy:\", train_acc)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Important features:\", important_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
